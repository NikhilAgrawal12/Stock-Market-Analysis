{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c467d940-8454-4950-b83a-65279598a2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics for the Year: 2019\n",
      "               μ(R)      σ(R)  |R−|     μ(R−)     σ(R−)  |R+|     μ(R+)  \\\n",
      "Wednesday  0.000222  0.018978  24.0 -0.015064  0.013881  27.0  0.013809   \n",
      "Thursday  -0.001200  0.021968  26.0 -0.015676  0.018712  24.0  0.014482   \n",
      "Friday    -0.000341  0.019508  25.0 -0.015659  0.011051  26.0  0.014388   \n",
      "Monday     0.000098  0.017615  22.0 -0.014629  0.010320  26.0  0.012560   \n",
      "Tuesday   -0.002525  0.019036  28.0 -0.016757  0.010654  24.0  0.014079   \n",
      "\n",
      "              σ(R+)  \n",
      "Wednesday  0.010712  \n",
      "Thursday   0.012412  \n",
      "Friday     0.013549  \n",
      "Monday     0.011897  \n",
      "Tuesday    0.011665  \n",
      "\n",
      "Statistics for the Year: 2020\n",
      "               μ(R)      σ(R)  |R−|     μ(R−)     σ(R−)  |R+|     μ(R+)  \\\n",
      "Thursday   0.001726  0.056787  25.0 -0.032563  0.029410  27.0  0.033476   \n",
      "Friday    -0.012840  0.039367  32.0 -0.033388  0.027539  17.0  0.025839   \n",
      "Monday     0.000765  0.058377  24.0 -0.036065  0.026369  24.0  0.037595   \n",
      "Tuesday   -0.008417  0.048282  30.0 -0.038677  0.027543  22.0  0.032847   \n",
      "Wednesday -0.009704  0.042515  29.0 -0.036298  0.035984  23.0  0.023829   \n",
      "\n",
      "              σ(R+)  \n",
      "Thursday   0.057877  \n",
      "Friday     0.027309  \n",
      "Monday     0.058632  \n",
      "Tuesday    0.039010  \n",
      "Wednesday  0.020841  \n",
      "\n",
      "Statistics for the Year: 2021\n",
      "               μ(R)      σ(R)  |R−|     μ(R−)     σ(R−)  |R+|     μ(R+)  \\\n",
      "Monday     0.002121  0.024882  22.0 -0.019183  0.011213  25.0  0.020869   \n",
      "Tuesday   -0.000127  0.022344  28.0 -0.015477  0.011643  24.0  0.017783   \n",
      "Wednesday  0.003143  0.027883  21.0 -0.021001  0.019210  31.0  0.019498   \n",
      "Thursday  -0.006381  0.032362  32.0 -0.023873  0.022249  19.0  0.023079   \n",
      "Friday    -0.004395  0.027478  30.0 -0.021062  0.019991  20.0  0.020605   \n",
      "\n",
      "              σ(R+)  \n",
      "Monday     0.017159  \n",
      "Tuesday    0.018064  \n",
      "Wednesday  0.019780  \n",
      "Thursday   0.024422  \n",
      "Friday     0.015519  \n",
      "\n",
      "Statistics for the Year: 2022\n",
      "               μ(R)      σ(R)  |R−|     μ(R−)     σ(R−)  |R+|     μ(R+)  \\\n",
      "Monday    -0.002166  0.030895  21.0 -0.027115  0.022551  24.0  0.019663   \n",
      "Tuesday    0.003193  0.032496  22.0 -0.025665  0.020044  30.0  0.024356   \n",
      "Wednesday  0.000729  0.028418  25.0 -0.024213  0.014677  27.0  0.023823   \n",
      "Thursday  -0.002148  0.030169  25.0 -0.027006  0.017150  26.0  0.021754   \n",
      "Friday    -0.004261  0.027026  29.0 -0.022635  0.014451  22.0  0.019958   \n",
      "\n",
      "              σ(R+)  \n",
      "Monday     0.017840  \n",
      "Tuesday    0.021704  \n",
      "Wednesday  0.015272  \n",
      "Thursday   0.018053  \n",
      "Friday     0.019493  \n",
      "\n",
      "Statistics for the Year: 2023\n",
      "               μ(R)      σ(R)  |R−|     μ(R−)     σ(R−)  |R+|     μ(R+)  \\\n",
      "Tuesday    0.000392  0.016978  23.0 -0.014057  0.009088  28.0  0.012260   \n",
      "Wednesday -0.001470  0.021788  26.0 -0.017996  0.014388  26.0  0.015056   \n",
      "Thursday  -0.001649  0.020381  26.0 -0.017764  0.011854  25.0  0.015110   \n",
      "Friday     0.000988  0.017766  30.0 -0.010170  0.008105  21.0  0.016930   \n",
      "Monday     0.002121  0.015413  20.0 -0.012273  0.009799  25.0  0.013636   \n",
      "\n",
      "              σ(R+)  \n",
      "Tuesday    0.011940  \n",
      "Wednesday  0.013903  \n",
      "Thursday   0.012046  \n",
      "Friday     0.015499  \n",
      "Monday     0.006980  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('AAL.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Extract Year and Weekday from the Date column\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Weekday'] = data['Date'].dt.day_name()\n",
    "\n",
    "# Add a new column 'Return' to calculate daytime returns\n",
    "data['Return'] = (data['Close'] - data['Open']) / data['Open']\n",
    "\n",
    "# Initialize a dictionary to store results for each year\n",
    "yearly_weekly_stats = {}\n",
    "\n",
    "# Loop through each year\n",
    "for year in data['Year'].unique():\n",
    "    yearly_stats = {}\n",
    "    \n",
    "    # Filter the data for the current year\n",
    "    year_data = data[data['Year'] == year]\n",
    "    \n",
    "    # Loop through each weekday to compute statistics\n",
    "    for day in year_data['Weekday'].unique():\n",
    "        day_data = year_data[year_data['Weekday'] == day]\n",
    "        \n",
    "        # All daytime returns (R)\n",
    "        R = day_data['Return']\n",
    "        \n",
    "        # Negative returns (R−)\n",
    "        R_neg = R[R < 0]\n",
    "        \n",
    "        # Non-negative returns (R+)\n",
    "        R_pos = R[R >= 0]\n",
    "        \n",
    "        # Store statistics for the current day of the week\n",
    "        yearly_stats[day] = {\n",
    "            'μ(R)': R.mean(),\n",
    "            'σ(R)': R.std(),\n",
    "            '|R−|': len(R_neg),\n",
    "            'μ(R−)': R_neg.mean() if len(R_neg) > 0 else np.nan,\n",
    "            'σ(R−)': R_neg.std() if len(R_neg) > 0 else np.nan,\n",
    "            '|R+|': len(R_pos),\n",
    "            'μ(R+)': R_pos.mean() if len(R_pos) > 0 else np.nan,\n",
    "            'σ(R+)': R_pos.std() if len(R_pos) > 0 else np.nan\n",
    "        }\n",
    "    \n",
    "    # Add the statistics for this year to the overall dictionary\n",
    "    yearly_weekly_stats[year] = yearly_stats\n",
    "\n",
    "# Display the results for each year\n",
    "for year, stats in yearly_weekly_stats.items():\n",
    "    print(f\"\\nStatistics for the Year: {year}\")\n",
    "    stats_df = pd.DataFrame(stats).T\n",
    "    print(stats_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a3863-e49a-4809-a1cc-3d423dcef617",
   "metadata": {},
   "source": [
    "3. Are there more days with negative or non-negative daytime returns?\n",
    "\n",
    "\n",
    "To answer this question, we compare the values of |R−| (number of negative return days) and |R+| (number of non-negative return days) for each year and each weekday.\n",
    "\n",
    "In most years and for most days of the week, the |R+| (non-negative days) is quite close to |R−| (negative days), but in some cases (like Fridays and Tuesdays), there are more negative return days.\n",
    "\n",
    "\n",
    "For example, in 2020:\n",
    "\n",
    "\n",
    "Tuesday: 30 negative days (|R−|) vs. 22 non-negative days (|R+|).\n",
    "\n",
    "\n",
    "Friday: 32 negative days (|R−|) vs. 17 non-negative days (|R+|).\n",
    "\n",
    "\n",
    "This suggests that certain days of the week tend to have more negative returns, especially Fridays in some years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0813d3-df0f-42d6-9858-245d74e567ce",
   "metadata": {},
   "source": [
    "4. Does your stock lose more on a \"down\" day than it gains on an \"up\" day?\n",
    "\n",
    "\n",
    "To answer this, we compare the values of μ(R−) (average loss on negative days) and μ(R+) (average gain on non-negative days).\n",
    "\n",
    "For most of the years shown, the magnitude of μ(R−) (average loss) is larger than μ(R+) (average gain).\n",
    "\n",
    "\n",
    "For example, in 2020 on Friday:\n",
    "\n",
    "\n",
    "μ(R−) = -0.03388 (loss)\n",
    "μ(R+) = 0.025839 (gain)\n",
    "\n",
    "\n",
    "This indicates that the stock tends to lose more on down days than it gains on up days, implying that negative days are more pronounced in terms of loss than the positive days are in terms of gains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7109df98-69a4-4f95-bf03-949892a7a839",
   "metadata": {},
   "source": [
    "5. Are these results the same across days of the week?\n",
    "\n",
    "\n",
    "The results show some variability across days of the week:\n",
    "\n",
    "\n",
    "Fridays often show a higher number of negative return days (|R−|) and more pronounced losses (μ(R−)).\n",
    "\n",
    "\n",
    "Mondays and Wednesdays tend to have a more balanced distribution between negative and non-negative returns, with moderate values for both μ(R−) and μ(R+).\n",
    "\n",
    "\n",
    "Thus, the behavior of the stock is not exactly the same across different days of the week. For instance, Fridays and some Tuesdays show stronger negative trends, while Mondays and Wednesdays appear to be more stable.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "\n",
    "Negative vs. Non-negative Days: There are more negative return days than non-negative ones, especially on certain weekdays like Fridays.\n",
    "\n",
    "\n",
    "Loss vs. Gain: The stock tends to lose more on down days than it gains on up days, particularly on Fridays and Tuesdays.\n",
    "\n",
    "\n",
    "Day of the Week Variability: The results vary by day of the week, with Fridays often being more negative compared to other days, while Mondays and Wednesdays are more balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c06e9a-51ba-4094-b5d1-918a6a42686f",
   "metadata": {},
   "source": [
    "1. Are there any patterns across days of the week?\n",
    "\n",
    "\n",
    "Yes, based on the tables for different years, we can observe some patterns across the days of the week:\n",
    "\n",
    "\n",
    "Fridays tend to show more negative returns (higher |R−|) and often have larger average losses (μ(R−)) compared to the gains (μ(R+)) on positive days.\n",
    "\n",
    "\n",
    "Example: In 2020, Friday had 32 negative days and an average loss of -0.03388, compared to only 17 non-negative days with an average gain of 0.025839.\n",
    "\n",
    "\n",
    "Mondays tend to have more balanced returns, with fewer extreme losses and smaller deviations. In some years, Mondays show a small positive return on average.\n",
    "\n",
    "\n",
    "Example: In 2019, Monday had an average return of 0.000098 with nearly equal negative and non-negative days.\n",
    "\n",
    "\n",
    "Wednesdays also tend to be relatively stable, with fewer extreme losses compared to other days.\n",
    "\n",
    "\n",
    "Example: In 2021, Wednesday had an average return of 0.001343, and the number of negative and non-negative days was nearly equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f023631-82d7-4124-b733-30fff081d024",
   "metadata": {},
   "source": [
    "2. Are there any patterns across different years for the same day of the week?\n",
    "\n",
    "\n",
    ">Yes, there are some recurring trends for certain days of the week across different years:\n",
    "\n",
    "Fridays consistently show more negative returns across multiple years. This is visible in the data for 2019, 2020, 2021, and 2022, where Fridays have a larger number of negative days compared to other weekdays.\n",
    "\n",
    "\n",
    "Tuesdays also tend to show a similar pattern, with more negative days in most years. For instance, in 2020, 2021, and 2022, Tuesdays show higher negative returns and larger losses on average.\n",
    "\n",
    "\n",
    "Mondays are relatively stable across different years, often having a nearly balanced number of positive and negative days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d8dac1-9644-4094-a6f7-f08ea913d029",
   "metadata": {},
   "source": [
    "3. What are the best and worst days of the week to be invested for each year?\n",
    "\n",
    "\n",
    "Based on the mean returns (μ(R)) and the number of positive and negative days, we can determine the best and worst days of the week for each year:\n",
    "\n",
    "2019:\n",
    "\n",
    "\n",
    "Best day: Monday (μ(R) = 0.000098) with balanced positive and negative returns.\n",
    "Worst day: Friday (μ(R) = -0.000341) with more negative days (25 negative days).\n",
    "\n",
    "\n",
    "2020:\n",
    "\n",
    "\n",
    "Best day: Thursday (μ(R) = 0.001726) with relatively balanced positive and negative returns.\n",
    "Worst day: Friday (μ(R) = -0.012840) with 32 negative days.\n",
    "\n",
    "\n",
    "2021:\n",
    "\n",
    "\n",
    "Best day: Monday (μ(R) = 0.002121) with a balanced return profile.\n",
    "Worst day: Friday (μ(R) = -0.004395) with more negative days.\n",
    "\n",
    "\n",
    "2022:\n",
    "\n",
    "\n",
    "Best day: Tuesday (μ(R) = 0.003193), showing positive returns overall.\n",
    "Worst day: Friday (μ(R) = -0.004261) with more negative days (29 negative days).\n",
    "\n",
    "\n",
    "2023:\n",
    "\n",
    "\n",
    "Best day: Monday (μ(R) = 0.002121) with balanced returns.\n",
    "Worst day: Wednesday (μ(R) = -0.001470) with more negative days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09451f1-8ff6-4826-b601-bb5fd7c0b956",
   "metadata": {},
   "source": [
    "4. Do these days change from year to year for your stock?\n",
    "\n",
    "   \n",
    "Yes, the best and worst days to be invested change from year to year:\n",
    "\n",
    "\n",
    "For example, Monday was the best day in 2019, 2021, and 2023, but in 2020, Thursday was the best day.\n",
    "\n",
    "\n",
    "Similarly, Friday tends to be the worst day in most years, but in 2023, Wednesday showed more negative returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d245da5-988e-4e50-b522-8cfaad203714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate Statistics Across All 5 Years:\n",
      "           Aggregate μ(R)  Aggregate σ(R)\n",
      "Wednesday       -0.001416        0.027916\n",
      "Thursday        -0.001930        0.032333\n",
      "Friday          -0.004170        0.026229\n",
      "Monday           0.000588        0.029436\n",
      "Tuesday         -0.001497        0.027827\n",
      "\n",
      "Best day to invest: Monday with average μ(R) = 0.000588\n",
      "Worst day to invest: Friday with average μ(R) = -0.004170\n",
      "\n",
      "Total trading days: 1258\n",
      "Number of trading days outside μ ± 2σ: 54\n",
      "Expected number of days outside μ ± 2σ (5%): 63\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('AAL.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Extract Year and Weekday from the Date column\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Weekday'] = data['Date'].dt.day_name()\n",
    "\n",
    "# Add a new column 'Return' to calculate daytime returns\n",
    "data['Return'] = (data['Close'] - data['Open']) / data['Open']\n",
    "\n",
    "# Initialize a dictionary to store results for each year\n",
    "yearly_weekly_stats = {}\n",
    "\n",
    "# Loop through each year\n",
    "for year in data['Year'].unique():\n",
    "    yearly_stats = {}\n",
    "    \n",
    "    # Filter the data for the current year\n",
    "    year_data = data[data['Year'] == year]\n",
    "    \n",
    "    # Loop through each weekday to compute statistics\n",
    "    for day in year_data['Weekday'].unique():\n",
    "        day_data = year_data[year_data['Weekday'] == day]\n",
    "        \n",
    "        # All daytime returns (R)\n",
    "        R = day_data['Return']\n",
    "        \n",
    "        # Negative returns (R−)\n",
    "        R_neg = R[R < 0]\n",
    "        \n",
    "        # Non-negative returns (R+)\n",
    "        R_pos = R[R >= 0]\n",
    "        \n",
    "        # Store statistics for the current day of the week\n",
    "        yearly_stats[day] = {\n",
    "            'μ(R)': R.mean(),\n",
    "            'σ(R)': R.std(),\n",
    "            '|R−|': len(R_neg),\n",
    "            'μ(R−)': R_neg.mean() if len(R_neg) > 0 else np.nan,\n",
    "            'σ(R−)': R_neg.std() if len(R_neg) > 0 else np.nan,\n",
    "            '|R+|': len(R_pos),\n",
    "            'μ(R+)': R_pos.mean() if len(R_pos) > 0 else np.nan,\n",
    "            'σ(R+)': R_pos.std() if len(R_pos) > 0 else np.nan\n",
    "        }\n",
    "    \n",
    "    # Add the statistics for this year to the overall dictionary\n",
    "    yearly_weekly_stats[year] = yearly_stats\n",
    "\n",
    "# To store the aggregate statistics for 5 years\n",
    "aggregate_stats = {}\n",
    "\n",
    "# Loop through each weekday and compute aggregate mean and std across 5 years\n",
    "for day in data['Weekday'].unique():\n",
    "    mu_r_list = []\n",
    "    sigma_r_list = []\n",
    "    \n",
    "    # Collect the mean and standard deviation for each year\n",
    "    for year, stats in yearly_weekly_stats.items():\n",
    "        if day in stats:\n",
    "            mu_r_list.append(stats[day]['μ(R)'])\n",
    "            sigma_r_list.append(stats[day]['σ(R)'])\n",
    "    \n",
    "    # Calculate the aggregate mean and std\n",
    "    aggregate_stats[day] = {\n",
    "        'Aggregate μ(R)': np.mean(mu_r_list),\n",
    "        'Aggregate σ(R)': np.mean(sigma_r_list)\n",
    "    }\n",
    "\n",
    "# Convert aggregate statistics to DataFrame\n",
    "aggregate_stats_df = pd.DataFrame(aggregate_stats).T\n",
    "\n",
    "# Display aggregate statistics\n",
    "print(\"Aggregate Statistics Across All 5 Years:\")\n",
    "print(aggregate_stats_df)\n",
    "\n",
    "# Determine the best and worst days based on the aggregate mean return\n",
    "best_day = aggregate_stats_df['Aggregate μ(R)'].idxmax()\n",
    "worst_day = aggregate_stats_df['Aggregate μ(R)'].idxmin()\n",
    "\n",
    "print(f\"\\nBest day to invest: {best_day} with average μ(R) = {aggregate_stats_df['Aggregate μ(R)'].max():.6f}\")\n",
    "print(f\"Worst day to invest: {worst_day} with average μ(R) = {aggregate_stats_df['Aggregate μ(R)'].min():.6f}\")\n",
    "\n",
    "# Step 2: Calculate how many days fall outside the μ ± 2σ range\n",
    "# Calculate the overall mean (μ) and std (σ) for the entire dataset\n",
    "overall_mean = data['Return'].mean()\n",
    "overall_std = data['Return'].std()\n",
    "\n",
    "# Calculate μ - 2σ and μ + 2σ\n",
    "lower_bound = overall_mean - 2 * overall_std\n",
    "upper_bound = overall_mean + 2 * overall_std\n",
    "\n",
    "# Find the number of days where returns are outside μ ± 2σ\n",
    "outliers = data[(data['Return'] < lower_bound) | (data['Return'] > upper_bound)]\n",
    "\n",
    "# Number of outlier days\n",
    "num_outliers = len(outliers)\n",
    "\n",
    "# Total trading days\n",
    "total_days = len(data)\n",
    "\n",
    "# Expected number of outliers based on a normal distribution (5% of total days)\n",
    "expected_outliers = total_days * 0.05\n",
    "\n",
    "# Display the results\n",
    "print(f\"\\nTotal trading days: {total_days}\")\n",
    "print(f\"Number of trading days outside μ ± 2σ: {num_outliers}\")\n",
    "print(f\"Expected number of days outside μ ± 2σ (5%): {round(expected_outliers)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b912b2-29e3-43f9-8541-885530c032a6",
   "metadata": {},
   "source": [
    "Is It Consistent with Normality?\n",
    "\n",
    "\n",
    "Actual Outliers: 54 days (around 4.29% of the total days) fall outside the μ ± 2σ range.\n",
    "\n",
    "\n",
    "Expected Outliers: Based on the assumption of normality, we expect 62.9 days (5% of the total days) to be outliers.\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "\n",
    "The observed number of outlier days (54) is close to the expected number (62.9), but slightly lower.\n",
    "\n",
    "\n",
    "This small difference suggests that the returns are fairly consistent with normality, though the distribution might not perfectly match a normal distribution. In practice, financial returns often exhibit fat tails or higher kurtosis, meaning that extreme values (outliers) can occur more frequently than in a normal distribution.\n",
    "\n",
    "\n",
    "In this case, however, the results show that stock's daytime returns are reasonably close to a normal distribution, though slightly fewer extreme days were observed than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d61820d-da7d-4e75-9bd7-ed898f9f479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final balance after 5 years with p = 1: $17140124.67\n",
      "Number of days to reach $882: 299 trading days\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('AAL.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Sort the data by date just in case it's not sorted\n",
    "data = data.sort_values('Date')\n",
    "\n",
    "# Calculate daytime returns (as done previously)\n",
    "data['Return'] = (data['Close'] - data['Open']) / data['Open']\n",
    "\n",
    "# Question 4, Part 1: Simulate for p = 1 (oracle is always correct)\n",
    "starting_balance = 100  # Starting with $100\n",
    "balance = starting_balance\n",
    "\n",
    "# Oracle is always correct, so we apply all positive returns (because p = 1)\n",
    "for ret in data['Return']:\n",
    "    if ret > 0:  # Only make money on positive return days\n",
    "        balance *= (1 + ret)\n",
    "\n",
    "# Final balance after 5 years of trading with oracle\n",
    "print(f\"Final balance after 5 years with p = 1: ${balance:.2f}\")\n",
    "\n",
    "# Question 4, Part 2: How many days to reach the desired amount\n",
    "# Last 3 digits of BU ID (782 as per your BU ID)\n",
    "bu_id_last_3_digits = 782  # Your BU ID\n",
    "desired_amount = starting_balance + bu_id_last_3_digits\n",
    "\n",
    "balance = starting_balance\n",
    "days = 0\n",
    "\n",
    "# Loop over the returns and track the number of days to reach the desired amount\n",
    "for ret in data['Return']:\n",
    "    if ret > 0:  # Oracle is correct, apply positive returns\n",
    "        balance *= (1 + ret)\n",
    "    days += 1\n",
    "    if balance >= desired_amount:\n",
    "        break  # Stop once we've reached the desired amount\n",
    "\n",
    "# Print how many days it took to reach the desired amount\n",
    "print(f\"Number of days to reach ${desired_amount}: {days} trading days\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b336c1-f73d-4876-9d44-f6034756086e",
   "metadata": {},
   "source": [
    "### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff0b4c4e-6ded-4ce9-948f-218f0c65f362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final balance after 5 years (Buy-and-Hold): $6.45\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('AAL.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Sort the data by date just in case it's not sorted\n",
    "data = data.sort_values('Date')\n",
    "\n",
    "# Calculate daytime returns for buy-and-hold strategy (Close - Open) / Open\n",
    "data['Return'] = (data['Close'] - data['Open']) / data['Open']\n",
    "\n",
    "### Part 1: Final Balance after 5 Years of Buy-and-Hold ###\n",
    "starting_balance = 100  # Start with $100\n",
    "balance = starting_balance\n",
    "\n",
    "# Apply buy-and-hold for each trading day\n",
    "for ret in data['Return']:\n",
    "    balance *= (1 + ret)\n",
    "\n",
    "# Final balance after 5 years of trading with buy-and-hold strategy\n",
    "print(f\"Final balance after 5 years (Buy-and-Hold): ${balance:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cddd3-e816-404d-bfa3-76ca4a8e406f",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb998171-0eef-4f9e-9dd2-3a9a03a00834",
   "metadata": {},
   "source": [
    "The results of the buy-and-hold strategy in Question 5 show a significantly lower final balance compared to the results obtained in Question 4 with the oracle strategy.\n",
    "\n",
    "\n",
    "In Question 4, where the oracle had perfect predictions with 𝑝=1\n",
    "\n",
    "\n",
    "p=1, the final balance reached an impressive $17,140,124.67 after 5 years. This is because the oracle only allowed us to invest on days with positive returns, completely avoiding losses.\n",
    "\n",
    "\n",
    "In contrast, in Question 5, using the buy-and-hold strategy, the final balance after 5 years was just $6.45. This strategy exposed the investment to both positive and negative returns, and over time, the negative returns outweighed the positive ones, causing the balance to decline substantially.\n",
    "\n",
    "\n",
    "In summary, the oracle strategy in Question 4 resulted in exponential growth due to avoiding negative returns, whereas the buy-and-hold strategy in Question 5 led to a sharp decrease in balance due to the compounding of both gains and losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a858dc8-f48e-487d-8ca7-34e0ecbea23b",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b7f4217-4643-4583-b199-56bb337344ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final balance with Winter Vacation (No trading in Dec, Jan, Feb): $6.31\n"
     ]
    }
   ],
   "source": [
    "winter_vacation_data = data[~data['Date'].dt.month.isin([12, 1, 2])]\n",
    "\n",
    "# Reset balance and simulate buy-and-hold without trading in Dec, Jan, and Feb\n",
    "balance = starting_balance\n",
    "for ret in winter_vacation_data['Return']:\n",
    "    balance *= (1 + ret)\n",
    "\n",
    "print(f\"Final balance with Winter Vacation (No trading in Dec, Jan, Feb): ${balance:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95960ba4-f05f-40d1-bcb6-130fe796c34c",
   "metadata": {},
   "source": [
    "Based on the final balance of 6.31 dollars, we can conclude that taking a winter vacation does not significantly improve the outcome compared to the regular buy-and-hold strategy, which resulted in a final balance of 6.45 dollars..\n",
    "\n",
    "Key Observations:\n",
    "\n",
    "\n",
    "The difference between the regular buy-and-hold strategy (6.45 dollars) and the winter vacation strategy (6.31 dollars) is minimal, indicating that avoiding trading during December, January, and February had little impact on the overall results.\n",
    "\n",
    "\n",
    "Both strategies resulted in a significant reduction from the initial $100, showing that the negative returns throughout the year had a stronger impact on the investment, and skipping the winter months did not offer much protection from losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d6f35665-3e36-4b58-b265-295191983584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final balance for Daytime Buy-and-Hold (B&H): $6.45\n",
      "Final balance skipping January: $6.02\n",
      "Final balance skipping February: $6.11\n",
      "Final balance skipping March: $14.20\n",
      "Final balance skipping April: $13.17\n",
      "Final balance skipping May: $8.07\n",
      "Final balance skipping June: $6.27\n",
      "Final balance skipping July: $7.59\n",
      "Final balance skipping August: $8.71\n",
      "Final balance skipping September: $7.32\n",
      "Final balance skipping October: $7.79\n",
      "Final balance skipping November: $8.61\n",
      "Final balance skipping December: $7.14\n",
      "\n",
      "Best month to take a vacation: March with final balance: $14.20\n",
      "Worst month to take a vacation: January with final balance: $6.02\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to map month numbers to month names\n",
    "month_names = {\n",
    "    1: \"January\", 2: \"February\", 3: \"March\", 4: \"April\", \n",
    "    5: \"May\", 6: \"June\", 7: \"July\", 8: \"August\", \n",
    "    9: \"September\", 10: \"October\", 11: \"November\", 12: \"December\"\n",
    "}\n",
    "\n",
    "# Calculate the balance for regular buy-and-hold (no skipping any month)\n",
    "balance = starting_balance\n",
    "for ret in data['Return']:\n",
    "    balance *= (1 + ret)\n",
    "\n",
    "# Add the Daytime Buy-and-Hold (B&H) strategy to the results\n",
    "print(f\"Final balance for Daytime Buy-and-Hold (B&H): ${balance:.2f}\")\n",
    "results = [(\"Daytime Buy-and-Hold (B&H)\", balance)]\n",
    "\n",
    "# Function to calculate final balance when skipping a particular month\n",
    "def calculate_balance_skipping_month(skip_month):\n",
    "    balance = starting_balance\n",
    "    # Filter out the rows for the given month\n",
    "    month_vacation_data = data[~(data['Date'].dt.month == skip_month)]\n",
    "    for ret in month_vacation_data['Return']:\n",
    "        balance *= (1 + ret)\n",
    "    return balance\n",
    "\n",
    "# Loop over all months from January (1) to December (12)\n",
    "for month in range(1, 13):\n",
    "    final_balance = calculate_balance_skipping_month(month)\n",
    "    month_name = month_names[month]\n",
    "    results.append((month_name, final_balance))\n",
    "    print(f\"Final balance skipping {month_name}: ${final_balance:.2f}\")\n",
    "\n",
    "# Find the best and worst months to take a vacation\n",
    "best_month = max(results[1:], key=lambda x: x[1])  # Skip the first result (B&H)\n",
    "worst_month = min(results[1:], key=lambda x: x[1])  # Skip the first result (B&H)\n",
    "\n",
    "print(f\"\\nBest month to take a vacation: {best_month[0]} with final balance: ${best_month[1]:.2f}\")\n",
    "print(f\"Worst month to take a vacation: {worst_month[0]} with final balance: ${worst_month[1]:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5d4241fa-72a8-4de0-810c-bc51b4f32672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final balance for Daytime Buy-and-Hold: $6.45\n",
      "Final balance with p = 0.0: $0.00\n",
      "Final balance with p = 0.1: $0.00\n",
      "Final balance with p = 0.2: $0.01\n",
      "Final balance with p = 0.3: $0.14\n",
      "Final balance with p = 0.4: $2.03\n",
      "Final balance with p = 0.5: $40.37\n",
      "Final balance with p = 0.6: $266.81\n",
      "Final balance with p = 0.7: $3158.04\n",
      "Final balance with p = 0.8: $80254.20\n",
      "Final balance with p = 0.9: $846076.41\n",
      "Final balance with p = 1.0: $17140124.67\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Function to simulate the portfolio value based on p\n",
    "def simulate_portfolio_with_oracle(p, data):\n",
    "    balance = 100  # Start with $100\n",
    "    for ret in data['Return']:\n",
    "        # Generate a random number between 0 and 1\n",
    "        r = random.random()\n",
    "        # If r <= p, oracle gives the correct label (positive return is used)\n",
    "        # Otherwise, the opposite label is used (negative return is used)\n",
    "        if (r <= p and ret >= 0) or (r > p and ret < 0):\n",
    "            balance *= (1 + ret)\n",
    "    return balance\n",
    "\n",
    "# Daytime buy-and-hold without Oracle\n",
    "balance_bh = 100\n",
    "for ret in data['Return']:\n",
    "    balance_bh *= (1 + ret)\n",
    "\n",
    "print(f\"Final balance for Daytime Buy-and-Hold: ${balance_bh:.2f}\")\n",
    "\n",
    "# Dictionary to store results for different values of p\n",
    "results = [(\"Daytime Buy-and-Hold\", balance_bh)]\n",
    "\n",
    "# List of p values to test\n",
    "p_values = [i / 10 for i in range(11)]  # 0, 0.1, 0.2, ..., 1.0\n",
    "\n",
    "# Simulate for each p value\n",
    "for p in p_values:\n",
    "    final_balance = simulate_portfolio_with_oracle(p, data)\n",
    "    results.append((f\"p = {p}\", final_balance))\n",
    "    print(f\"Final balance with p = {p}: ${final_balance:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc24c1-2e0a-453e-a5be-be9a37a70091",
   "metadata": {},
   "source": [
    "Value of p= 4 (2.76) is closer to buy and hold than "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2414b249-d312-456b-8363-f204cb6dba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy                                 | Stock\n",
      "------------------------------------------------------\n",
      "Buy-and-Hold (B&H):                      | $6.45\n",
      "Daytime Buy-and-Hold (B&H):              | $6.45\n",
      "p = 1 (Never lose):                      | $17140124.67\n",
      "Miss 10 best daytimes:                   | $1.85\n",
      "Invested in 10 worst daytimes:           | $30.67\n",
      "Miss 5 best and invested in 5 worst:     | $1.41\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `data` is the dataset with 'Return' column\n",
    "\n",
    "# Sort returns to find the best and worst trading days\n",
    "sorted_returns_desc = data['Return'].sort_values(ascending=False)  # Best days at the top\n",
    "sorted_returns_asc = data['Return'].sort_values(ascending=True)    # Worst days at the top\n",
    "\n",
    "# Scenario a: Miss the 10 best trading days\n",
    "def scenario_a(data):\n",
    "    # Remove the 10 best trading days\n",
    "    remaining_returns = sorted_returns_desc[10:]  # Remove top 10 days\n",
    "    balance = 100\n",
    "    for ret in remaining_returns:\n",
    "        balance *= (1 + ret)\n",
    "    return balance\n",
    "\n",
    "# Scenario b: Invest in the 10 worst trading days\n",
    "def scenario_b(data):\n",
    "    # Only include the 10 worst trading days\n",
    "    worst_10_days = sorted_returns_asc[:10]  # Take the worst 10 days\n",
    "    balance = 100\n",
    "    for ret in worst_10_days:\n",
    "        balance *= (1 + ret)\n",
    "    return balance\n",
    "\n",
    "# Scenario c: Miss the 5 best trading days and invest in the 5 worst trading days\n",
    "def scenario_c(data):\n",
    "    # Remove the top 5 best days and include the worst 5 days\n",
    "    remaining_returns = pd.concat([sorted_returns_desc[5:], sorted_returns_asc[:5]])\n",
    "    balance = 100\n",
    "    for ret in remaining_returns:\n",
    "        balance *= (1 + ret)\n",
    "    return balance\n",
    "\n",
    "# Daytime Buy-and-Hold Strategy (B&H)\n",
    "def daytime_buy_and_hold(data):\n",
    "    balance = 100\n",
    "    for ret in data['Return']:\n",
    "        balance *= (1 + ret)\n",
    "    return balance\n",
    "\n",
    "# p = 1 (Never lose, perfect oracle)\n",
    "def perfect_oracle(data):\n",
    "    balance = 100\n",
    "    for ret in data['Return']:\n",
    "        if ret >= 0:\n",
    "            balance *= (1 + ret)  # Only positive returns are considered\n",
    "    return balance\n",
    "\n",
    "# Calculate the balances for each strategy\n",
    "buy_and_hold_balance = daytime_buy_and_hold(data)\n",
    "perfect_oracle_balance = perfect_oracle(data)\n",
    "miss_10_best_balance = scenario_a(data)\n",
    "invest_10_worst_balance = scenario_b(data)\n",
    "miss_5_best_invest_5_worst_balance = scenario_c(data)\n",
    "\n",
    "# Print the results in a table format\n",
    "print(\"Strategy                                 | Stock\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(f\"Buy-and-Hold (B&H):                      | ${buy_and_hold_balance:.2f}\")\n",
    "print(f\"Daytime Buy-and-Hold (B&H):              | ${buy_and_hold_balance:.2f}\")\n",
    "print(f\"p = 1 (Never lose):                      | ${perfect_oracle_balance:.2f}\")\n",
    "print(f\"Miss 10 best daytimes:                   | ${miss_10_best_balance:.2f}\")\n",
    "print(f\"Invested in 10 worst daytimes:           | ${invest_10_worst_balance:.2f}\")\n",
    "print(f\"Miss 5 best and invested in 5 worst:     | ${miss_5_best_invest_5_worst_balance:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ec907-284f-4359-91f7-2f725b3796b8",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f91bd-4862-41dd-9d16-13d2d2ac4bdc",
   "metadata": {},
   "source": [
    "Scenario (a): Missed the 10 Best Daytimes\n",
    "\n",
    "The final balance after missing the 10 best trading days is $1.85. This shows a significant decrease from the buy-and-hold strategy because the most profitable days were missed.\n",
    "\n",
    "\n",
    "Scenario (b): Invested in the 10 Worst Daytimes\n",
    "\n",
    "The final balance after investing in the 10 worst trading days is $30.67. Surprisingly, this shows a lesser decrease than missing the 10 best days, which implies that the worst days weren’t as damaging compared to the profits of the best days.\n",
    "\n",
    "\n",
    "Scenario (c): Missed the 5 Best Daytimes and Invested in the 5 Worst Daytimes\n",
    "\n",
    "\n",
    "The final balance after missing the 5 best days and being invested in the 5 worst days is $1.41. This is even worse than missing the 10 best days alone, reflecting the combined negative impact of missing the best days and being invested in the worst days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e4ede6-2a12-44c2-ada9-f43f6d591331",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d97da-ba8a-498d-81e4-3f5acc45d089",
   "metadata": {},
   "source": [
    "I lose more by missing the best daytimes compared to being invested on the worst daytimes. This is evident from the balances:\n",
    "Missing the best 10 daytimes: $1.85.\n",
    "\n",
    "\n",
    "Investing in the worst 10 daytimes: $30.67.\n",
    "\n",
    "\n",
    "Missing the most profitable days has a greater impact on your overall balance than being invested in the least profitable days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359aa730-4f64-4fb2-9392-070fb5f7bbcf",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912d04e4-e989-47a1-b7f5-571b986467fe",
   "metadata": {},
   "source": [
    "\n",
    "p if you used a statistical oracle instead of an angry one:\n",
    "For Scenario (a) (missing the best 10 daytimes), the probability p could be estimated as 0.7 to 0.8, because the statistical oracle would likely predict positive returns on most days, but missing the top-performing days would still affect the balance.\n",
    "\n",
    "\n",
    "For Scenario (b) (investing in the worst 10 daytimes), the probability p could be 0.5 to 0.6, as the statistical oracle would still correctly predict many positive returns, but occasionally allow investment on negative-return days.\n",
    "\n",
    "\n",
    "For Scenario (c) (missing 5 best and investing in 5 worst daytimes), the probability p could be 0.5, reflecting a roughly even mix of good and bad predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef907d9-9d61-41b9-b358-c20c3eef9fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
